{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532096ca-8f23-4e98-a1b9-4d55f9870ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import snowflake.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f91aafef-efa4-4185-8716-f3f0c541516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string = \"mongodb+srv://mihir:1234@cluster0.7os7mbu.mongodb.net/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ebfbd28-2172-407e-9fc3-181918b6cdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB Atlas successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "    mongo_db = mongo_client[\"test\"]\n",
    "    \n",
    "    # Print connection success message\n",
    "    print(\"Connected to MongoDB Atlas successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with mongo_client and mongo_db\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to MongoDB Atlas: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e4164a-c7af-451a-b49c-4534444f59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "    snowflake_conn = snowflake.connector.connect(\n",
    "        user=\"mihir13\",\n",
    "        password=\"Snowflake@136\",\n",
    "        account=\"xumrpiu-em89221\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"DATA_ENGINE\",\n",
    "        schema=\"PUBLIC\",\n",
    "        role = \"ACCOUNTADMIN\"\n",
    "    )\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9557aca-bd39-49a0-804b-b669a46fcee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from collection 'performances' written to 'staging_raw_data/performances.csv'\n",
      "Data from collection 'users' written to 'staging_raw_data/users.csv'\n",
      "Data from collection 'admins' written to 'staging_raw_data/admins.csv'\n",
      "Data from collection 'inttrainingplans' written to 'staging_raw_data/inttrainingplans.csv'\n",
      "Data from collection 'Performancedata' written to 'staging_raw_data/Performancedata.csv'\n",
      "Data from collection 'emptrainingplans' written to 'staging_raw_data/emptrainingplans.csv'\n",
      "Data from collection 'modules' written to 'staging_raw_data/modules.csv'\n",
      "Data from collection 'Internplandata' written to 'staging_raw_data/Internplandata.csv'\n",
      "Data from collection 'Userdata' written to 'staging_raw_data/Userdata.csv'\n",
      "Data from collection 'Moduledata' written to 'staging_raw_data/Moduledata.csv'\n",
      "Data from collection 'Employeeplandata' written to 'staging_raw_data/Employeeplandata.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create raw_data folder if it doesn't exist\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    os.makedirs(\"staging_raw_data\")\n",
    "\n",
    "# Iterate over each collection\n",
    "for collection_name in mongo_db.list_collection_names():\n",
    "    # Retrieve data from collection\n",
    "    collection_data = list(mongo_db[collection_name].find())\n",
    "    \n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(collection_data)\n",
    "    \n",
    "    # Write DataFrame to CSV file\n",
    "    csv_file_path = f\"staging_raw_data/{collection_name}.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data from collection '{collection_name}' written to '{csv_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4560a8ef-dcf9-42b6-b190-67ee0d61d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5558a31e-579f-4d52-8534-df12e3929dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS admins (_id VARCHAR,fullName VARCHAR,email VARCHAR,password VARCHAR,phoneNumber VARCHAR,linkedInProfile VARCHAR,skills VARCHAR,location VARCHAR,collegeName VARCHAR,program VARCHAR,stream VARCHAR,__v VARCHAR)\n",
      "Data from 'admins.csv' inserted into 'admins' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS Employeeplandata (_id VARCHAR,date VARCHAR,time VARCHAR,topic VARCHAR,mentor VARCHAR,venue VARCHAR,planType VARCHAR,link VARCHAR)\n",
      "Data from 'Employeeplandata.csv' inserted into 'Employeeplandata' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS emptrainingplans (_id VARCHAR,date VARCHAR,time VARCHAR,trainingName VARCHAR,trainerName VARCHAR,trainingType VARCHAR,planType VARCHAR,link VARCHAR,__v VARCHAR)\n",
      "Data from 'emptrainingplans.csv' inserted into 'emptrainingplans' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS Internplandata (_id VARCHAR,planType VARCHAR,date VARCHAR,time VARCHAR,topic VARCHAR,mentor VARCHAR,venue VARCHAR,link VARCHAR,level VARCHAR)\n",
      "Data from 'Internplandata.csv' inserted into 'Internplandata' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS inttrainingplans (_id VARCHAR,date VARCHAR,time VARCHAR,trainingName VARCHAR,trainerName VARCHAR,trainingType VARCHAR,planType VARCHAR,link VARCHAR,__v VARCHAR)\n",
      "Data from 'inttrainingplans.csv' inserted into 'inttrainingplans' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS Moduledata (_id VARCHAR,name VARCHAR,desc VARCHAR,topics VARCHAR,stDate VARCHAR,enDate VARCHAR,audience VARCHAR)\n",
      "Data from 'Moduledata.csv' inserted into 'Moduledata' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS modules (_id VARCHAR,name VARCHAR,desc VARCHAR,topics VARCHAR,stDate VARCHAR,enDate VARCHAR,audience VARCHAR,__v VARCHAR)\n",
      "Data from 'modules.csv' inserted into 'modules' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS Performancedata (_id VARCHAR,userType VARCHAR,email VARCHAR,score VARCHAR)\n",
      "Data from 'Performancedata.csv' inserted into 'Performancedata' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS performances (_id VARCHAR,userType VARCHAR,email VARCHAR,score VARCHAR,__v VARCHAR)\n",
      "Data from 'performances.csv' inserted into 'performances' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS Userdata (_id VARCHAR,fullName VARCHAR,password VARCHAR,email VARCHAR,userType VARCHAR,phoneNumber VARCHAR,linkedInProfile VARCHAR,skills VARCHAR,location VARCHAR,collegeName VARCHAR,program VARCHAR,stream VARCHAR,isPasswordSet VARCHAR,resetPasswordToken VARCHAR,resetPasswordExpires VARCHAR)\n",
      "Data from 'Userdata.csv' inserted into 'Userdata' table in Snowflake.\n",
      "CREATE TABLE IF NOT EXISTS users (_id VARCHAR,fullName VARCHAR,userType VARCHAR,email VARCHAR,password VARCHAR,skills VARCHAR,isPasswordSet VARCHAR,resetPasswordToken VARCHAR,resetPasswordExpires VARCHAR,__v VARCHAR)\n",
      "Data from 'users.csv' inserted into 'users' table in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "# Create staging_raw_data folder if it doesn't exist\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    print(\"No data to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate over each CSV file in the staging_raw_data folder\n",
    "for filename in os.listdir(\"staging_raw_data\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Extract table name from filename (remove .csv extension)\n",
    "        table_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(f\"staging_raw_data/{filename}\")\n",
    "        \n",
    "        # Replace NaN values with empty strings\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Convert all data to string\n",
    "        df = df.astype(str)\n",
    "        # Create table in Snowflake if it doesn't exist\n",
    "        snowflake_cursor = snowflake_conn.cursor()\n",
    "        snowflake_cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "        create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "        for column in df.columns:\n",
    "            create_table_query += f'{column} VARCHAR,'\n",
    "        create_table_query = create_table_query[:-1] + \")\"  # Remove trailing comma\n",
    "        print(create_table_query)\n",
    "        snowflake_cursor.execute(create_table_query)\n",
    "        \n",
    "        # Prepare INSERT INTO statement\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({','.join(['%s'] * len(df.columns))})\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples (rows)\n",
    "        rows = [tuple(row) for row in df.itertuples(index=False)]\n",
    "        \n",
    "        # Execute bulk insert\n",
    "        snowflake_cursor.executemany(insert_query, rows)\n",
    "        snowflake_cursor.close()\n",
    "        \n",
    "        print(f\"Data from '{filename}' inserted into '{table_name}' table in Snowflake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d46072c-7ee7-4ca2-a484-4a5257789cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction\n",
    "snowflake_conn.commit()\n",
    "\n",
    "# Close Snowflake connection\n",
    "snowflake_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93137c93-24e7-4917-9938-4717f98e37bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
